datasci-getting-and-cleaning-data
=================================

A project submission for Data Science MOOC - Getting and cleaning data

Introduction
------------

The scientific discipline of interpreting and analysing data begins here.

Cleaning and tidying data is the first step in the data pipeline, but arguably the most important step and where most time is spent is preparing, cleaning and tidying data which can come in vast or small quantities from a plethora of different sources or from one single source for upstream analysis.

This project submission aims to provide an example of lessons learnt in the art of collecting and presenting tidy, documented, clearly understood and reproducible data from a given source. This will involve a decent amount of tranforming, munging, refactoring and understanding of the source of the data to fulfil the given objectives.

The source
----------

The data source in question is a set of publicly available datasets from the University of California, Irvine (UCI).
from their Center for Machine Learning and Intelligent Systems webpage. Currently, there are approximately 290 data sets available.
http://archive.ics.uci.edu/ml/datasets.html

The data sets
-------------
The specific data sets are the "Human Activity Recognition Using Smartphones Data Set" 

Abstract:

Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.

Source:

Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto. 
Smartlab - Non Linear Complex Systems Laboratory 
DITEN - Universit√† degli Studi di Genova, Genoa I-16145, Italy. 
activityrecognition@smartlab.ws 
www.smartlab.ws 

Data Set Information:

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. 

Citation:

Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

BiBTeX citation:

@misc{Bache+Lichman:2013 ,
author = "K. Bache and M. Lichman",
year = "2013",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

Additional data set specific citation:

[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012


The data:
---------
The direct link to this data set in zipped (.zip) form (UCI Link) :

http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip

File size:  62,556,944 bytes

MD5: d29710c9530a31f303801b6bc34bd895

SHA-1: 566456a9e02a23c2c0144674d9fa42a8b5390e71



 


